const axios = require('axios');
const cheerio = require('cheerio');
const fs = require('fs');
const path = require('path');
const url = require('url');

const inputUrl = process.argv[2]; // URL from command-line argument
const savePath = process.argv[4] || 'data'; // Custom path or default
const recursive = process.argv.includes('-r'); // Check for recursive flag
const maxDepth = parseInt(process.argv[process.argv.indexOf('-l') + 2]) || 5; // Set max depth

if (!inputUrl) {
    console.error('Please provide a URL.');
    process.exit(1);
}

// Function to create directory if it doesn't exist
function createDirectory(dir) {
    if (!fs.existsSync(dir)) {
        fs.mkdirSync(dir, { recursive: true }); // Ensure nested folders are created
    }
}

// Main function to scrape images
async function scrapeImages(currentUrl, depth = 0) {
    if (depth > maxDepth) return;

    try {
        const { data } = await axios.get(currentUrl);
        const $ = cheerio.load(data);

        // Find and download images
        $('img').each((_, img) => {
            const imgSrc = $(img).attr('src');
            downloadImage(imgSrc, depth); // Pass depth to downloadImage
        });

        // Recursively scrape links if -r flag is used
        if (recursive) {
            $('a').each((_, link) => {
                const linkHref = $(link).attr('href');
                if (linkHref && linkHref.startsWith('http')) {
                    scrapeImages(linkHref, depth + 1);
                }
            });
        }

    } catch (error) {
        console.error(`Failed to scrape ${currentUrl}: ${error.message}`);
    }
}

// Function to download images
async function downloadImage(imgSrc, depth) {
    // Ensure imgSrc is a fully qualified URL
    if (!imgSrc.startsWith('http')) {
        imgSrc = url.resolve(inputUrl, imgSrc); // Resolve relative URLs to absolute
    }

    const imgName = path.basename(imgSrc);
    const imgDir = path.join(savePath, depth.toString());
    createDirectory(imgDir); // Ensure the directory for the depth level exists
    const imgPath = path.join(imgDir, imgName);

    try {
        const response = await axios({
            url: imgSrc,
            method: 'GET',
            responseType: 'stream',
        });
        
        const writer = fs.createWriteStream(imgPath);
        response.data.pipe(writer);
        
        writer.on('finish', () => {
            console.log(`Downloaded: ${imgPath}`);
        });
        
        writer.on('error', (error) => {
            console.error(`Failed to write image ${imgSrc}: ${error.message}`);
        });
    } catch (error) {
        console.error(`Failed to download image ${imgSrc}: ${error.message}`);
    }
}

// Start the scraping process
createDirectory(savePath);
scrapeImages(inputUrl);
